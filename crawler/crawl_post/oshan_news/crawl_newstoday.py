from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import time
import requests
import json

# âœ… ê¸°ë³¸ ì…‹ì—…
def setup_driver():
    options = Options()
    options.add_argument("--headless")
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=options)

# âœ… ë‰´ìŠ¤ ì œëª© ê¸°ì¤€ìœ¼ë¡œ p íƒœê·¸ ë¬¶ì–´ì„œ ê¸°ì‚¬ ë¶„ë¦¬
def extract_articles_by_title_and_paragraphs(driver):
    elements = driver.find_elements(By.CSS_SELECTOR, "h2, p")

    articles = []
    current_article = {"title": None, "content": []}

    for el in elements:
        tag = el.tag_name.lower()
        text = el.text.strip()
        if not text:
            continue

        if tag == "h2":
            if current_article["title"] and current_article["content"]:
                articles.append({
                    "title": current_article["title"],
                    "content": "\n".join(current_article["content"])
                })
            current_article = {"title": text, "content": []}
        elif tag == "p":
            current_article["content"].append(text)

    if current_article["title"] and current_article["content"]:
        articles.append({
            "title": current_article["title"],
            "content": "\n".join(current_article["content"])
        })

    return articles

# âœ… ë‰´ìŠ¤ 1ì¼ì¹˜ í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_newstoday_article(date_str):
    url = f"https://futuresnow.gitbook.io/newstoday/{date_str}/news/today/bloomberg"
    driver = setup_driver()
    driver.get(url)
    time.sleep(3)

    # ìŠ¤í¬ë¡¤ ë‹¤ìš´
    scroll_pause_time = 1
    last_height = driver.execute_script("return document.body.scrollHeight")
    while True:
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(scroll_pause_time)
        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            break
        last_height = new_height

    try:
        articles = extract_articles_by_title_and_paragraphs(driver)
    except Exception as e:
        print(f"âŒ [{date_str}] ê¸°ì‚¬ íŒŒì‹± ì‹¤íŒ¨:", e)
        articles = []

    driver.quit()
    return articles

# âœ… POST ì „ì†¡ í•¨ìˆ˜
def post_article_to_server(title, content, date_str):
    url = "http://localhost:3000/api/news"
    headers = {"Content-Type": "application/json"}

    payload = {
        "title": title,
        "content": content,
        "link": f"https://futuresnow.gitbook.io/newstoday/{date_str}/news/today/bloomberg",
        "company": "newstoday",
        "keywords": "",
        "date": date_str
    }

    try:
        response = requests.post(url, headers=headers, data=json.dumps([payload], ensure_ascii=False))
        if response.status_code == 201:
            print(f"âœ… ì €ì¥ ì™„ë£Œ: {date_str} | {title}, {response.status_code}, {response.text}")
        else:
            print(f"âš ï¸ ì €ì¥ ì‹¤íŒ¨: {date_str} | {response.status_code}, {response.text}")
    except requests.RequestException as e:
        print(f"âŒ ìš”ì²­ ì˜¤ë¥˜: {e}")

# âœ… ë‚ ì§œ ë°˜ë³µ ì‹¤í–‰
def crawl_date_range(start_date_str, end_date_str):
    start_date = datetime.strptime(start_date_str, "%Y-%m-%d").date()
    end_date = datetime.strptime(end_date_str, "%Y-%m-%d").date()
    current_date = start_date

    while current_date <= end_date:
        date_str = current_date.strftime("%Y-%m-%d")
        print(f"ğŸ” [{date_str}] ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹œì‘...")
        articles = crawl_newstoday_article(date_str)

        if not articles:
            print(f"âš ï¸ [{date_str}] ë‰´ìŠ¤ ì—†ìŒ ë˜ëŠ” í¬ë¡¤ë§ ì‹¤íŒ¨")
        else:
            for article in articles:
                post_article_to_server(article["title"], article["content"], date_str)

        current_date += timedelta(days=1)

# âœ… ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    crawl_date_range("2024-11-01", datetime.today().strftime("%Y-%m-%d"))
